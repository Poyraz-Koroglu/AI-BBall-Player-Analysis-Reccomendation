import torch
from torch import nn
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, random_split
import os
from Train import *

# --- IMPORT YOUR CUSTOM CLASSES ---
# Ensure Dataset.py and model.py are in the same directory
from Dataset import BasketballPlayerDataset
from Model import ImprovementPredictor
'''
print(torch.cuda.is_available())
#print(torch.cuda.get_device_name(0))
'''

# ==========================================
# 1. CONFIGURATION
# ==========================================
CSV_FILE = "final_training_data_cumulative.csv"  # The file generated by your preprocessing script
BATCH_SIZE = 64
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

if DEVICE == "cuda":
    print("Using GPU")

print(f"ðŸš€ Execution started on: {DEVICE}")

# ==========================================
# 2. LOAD & PREPARE DATA
# ==========================================
if not os.path.exists(CSV_FILE):
    print(f"âŒ Error: '{CSV_FILE}' not found.")
    print("   -> Please run the preprocessing part of Dataset.py first to generate it!")
    exit()

print(f"Loading data from {CSV_FILE}...")
df = pd.read_csv(CSV_FILE)

# Initialize the Dataset
# Note: The class automatically picks up the 'Career' and 'Trend' columns we added
dataset = BasketballPlayerDataset(
    df=df,
    target_col='Improved',
    scale_features=True
)

print(f"Dataset ready: {len(dataset)} samples.")
print(f"Features: {len(dataset.numerical_cols)} numerical, {len(dataset.categorical_cols)} categorical.")

# Split into Train (80%) and Validation (20%)
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

# Create DataLoaders
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

# ==========================================
# 3. INITIALIZE MODEL
# ==========================================
# Dynamically calculate how many unique categories exist (for Embeddings)
cat_cardinalities = []
for col in dataset.categorical_cols:
    le = dataset.label_encoders[col]
    # Add +1 to safely handle any unknown categories
    cat_cardinalities.append(len(le.classes_) + 1)

# Initialize the Model
model = ImprovementPredictor(
    num_numerical_features=len(dataset.numerical_cols),
    categorical_cardinalities=cat_cardinalities,
    hidden_units=[128, 64] # Architecture: Input -> 128 -> 64 -> Output
)

# Setup Optimizer (Learning Rate will be set in train_model call)
optimizer = torch.optim.Adam(model.parameters())
criterion = nn.BCEWithLogitsLoss()

# ==========================================
# 4. RUN TRAINING
# ==========================================
print("\nðŸ”¥ Starting Training Loop...")

history = train_model(
    model,
    train_loader=train_loader,
    val_loader=val_loader,
    optimizer=optimizer,
    criterion=criterion,
    epochs=30,             # Maximum epochs
    learning_rate=0.001,   # Initial learning rate
    patience=5,            # Early stopping patience
    label_smoothing=0.1,   # 0.1 means we are 90% confident (good for sports noise)
    device=DEVICE,
    save_path="basketball_model_best.pth"
    )

# ==========================================
# 5. VISUALIZE RESULTS
# ==========================================
print("\nðŸ“Š Plotting Results...")

plt.figure(figsize=(12, 10))

# Plot 1: Accuracy
plt.subplot(2, 2, 1)
plt.plot(history['train_acc'], label='Train Acc', marker='o')
plt.plot(history['val_acc'], label='Val Acc', marker='o')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.legend()
plt.grid(True)

# Plot 2: Loss
plt.subplot(2, 2, 2)
plt.plot(history['train_loss'], label='Train Loss', marker='o')
plt.plot(history['val_loss'], label='Val Loss', marker='o')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)

# Plot 3: Detailed Batch Loss (to see convergence)
plt.subplot(2, 1, 2)
plt.plot(history['all_batch_losses'], alpha=0.3, color='gray', label='Batch Loss')
# Moving average for cleaner line
if len(history['all_batch_losses']) > 50:
    moving_avg = np.convolve(history['all_batch_losses'], np.ones(50)/50, mode='valid')
    plt.plot(moving_avg, color='blue', label='Moving Average')
plt.title('Training Progress (Per Batch)')
plt.xlabel('Batch Step')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

print("\nâœ… Train Finished. Best model saved to 'basketball_model_best.pth ")
